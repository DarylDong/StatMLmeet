{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set_style(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "nGrid = 64\n",
    "\n",
    "class zeldo_data:\n",
    "    def load_data():\n",
    "\n",
    "        z = 50\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z50 = hdf5_file[\"sims_z\" + str(z)]\n",
    "        \n",
    "        z = 0\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z0 = hdf5_file[\"sims_z\" + str(z)]\n",
    "     \n",
    "        train_test_split = 0.9\n",
    "        split = np.int(train_test_split*sim_z0.shape[0])\n",
    "        \n",
    "        train_data = sim_z0[0:split, :, :, :]\n",
    "        train_target = sim_z50[0:split, :, :, :]\n",
    "        test_data = sim_z0[split:, :, :, :]\n",
    "        test_target = sim_z50[split:, :, :, :]\n",
    "        \n",
    "        return (train_data, train_target), (test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "tf.flags.DEFINE_float('learning_rate', .0005, 'Initial learning rate.')\n",
    "tf.flags.DEFINE_integer('epochs', 1, 'Number of steps to run trainer.')\n",
    "tf.flags.DEFINE_integer('batch_size', 2, 'Minibatch size')\n",
    "tf.flags.DEFINE_integer('latent_dim', 8, 'Number of latent dimensions')\n",
    "tf.flags.DEFINE_integer('test_image_number', 5, 'Number of test images to recover during training')\n",
    "tf.flags.DEFINE_integer('inputs_decoder', 49, 'Size of decoder input layer')\n",
    "tf.flags.DEFINE_string('dataset', 'zeldo', 'Dataset name [mnist, zeldo, fashion-mnist]')\n",
    "tf.flags.DEFINE_string('logdir', './logs', 'Logs folder')\n",
    "tf.flags.DEFINE_bool('plot_latent', True, 'Plot latent space')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create results folders\n",
    "results_folder = os.path.join('Results', FLAGS.dataset)\n",
    "[os.makedirs(os.path.join(results_folder, folder)) for folder in ['Test', 'Train']\n",
    "    if not os.path.exists(os.path.join(results_folder, folder))]\n",
    "\n",
    "# Empty log folder\n",
    "try:\n",
    "    if not len(os.listdir(FLAGS.logdir)) == 0:\n",
    "        shutil.rmtree(FLAGS.logdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "# data = zeldo_data if FLAGS.dataset == 'zeldo'\n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create tf dataset\n",
    "with tf.variable_scope(\"DataPipe\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    dataset = dataset.map(lambda x: tf.image.convert_image_dtype([x], dtype=tf.float32))\n",
    "    dataset = dataset.batch(batch_size=FLAGS.batch_size).prefetch(FLAGS.batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    input_batch = iterator.get_next()\n",
    "    input_batch = tf.reshape(input_batch, shape=[-1, nGrid, nGrid, nGrid, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(X):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        x = tf.layers.conv3d(inputs=X, filters=64, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d(inputs=x, filters=64, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d(inputs=x, filters=64, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.flatten(x)\n",
    "\n",
    "        # Local latent variables\n",
    "        mean_ = tf.layers.dense(x, units=FLAGS.latent_dim, name='mean')\n",
    "        std_dev = tf.nn.softplus(tf.layers.dense(x, units=FLAGS.latent_dim), name='std_dev')  # softplus to force >0\n",
    "\n",
    "        # Reparametrization trick\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], FLAGS.latent_dim]), name='epsilon')\n",
    "        z = mean_ + tf.multiply(epsilon, std_dev)\n",
    "\n",
    "        return z, mean_, std_dev\n",
    "\n",
    "def decoder(z):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        x = tf.layers.dense(z, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        recovered_size = int(np.sqrt(FLAGS.inputs_decoder))\n",
    "        x = tf.reshape(x, [-1, recovered_size, recovered_size, recovered_size, 1])\n",
    "\n",
    "        x = tf.layers.conv3d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units= nGrid*nGrid*nGrid, activation=None)\n",
    "\n",
    "        x = tf.layers.dense(x, units=nGrid*nGrid*nGrid, activation=tf.nn.sigmoid)\n",
    "        img = tf.reshape(x, shape=[-1, nGrid, nGrid, nGrid, 1])\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-9e6168cfd626>:4: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-9e6168cfd626>:7: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-9e6168cfd626>:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-9e6168cfd626>:27: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d_transpose instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Link encoder and decoder\n",
    "z, mean_, std_dev = encoder(input_batch)\n",
    "output = decoder(z)\n",
    "\n",
    "# Reshape input and output to flat vectors\n",
    "flat_output = tf.reshape(output, [-1, nGrid*nGrid*nGrid])\n",
    "flat_input = tf.reshape(input_batch, [-1, nGrid*nGrid*nGrid])\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    img_loss = tf.reduce_sum(flat_input * -tf.log(flat_output) + (1 - flat_input) * -tf.log(1 - flat_output), 1)\n",
    "    latent_loss = 0.5 * tf.reduce_sum(tf.square(mean_) + tf.square(std_dev) - tf.log(tf.square(std_dev)) - 1, 1)\n",
    "    loss = tf.reduce_mean(img_loss + latent_loss)\n",
    "    tf.summary.scalar('batch_loss', loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "init_vars = [tf.local_variables_initializer(), tf.global_variables_initializer()]\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "with tf.Session(config=tf.ConfigProto()) as sess:\n",
    "\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "    sess.run(init_vars)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        print('Actual epoch: {}'.format(epoch))\n",
    "        print(epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "#         flag = True  # Show only first batch of epoch\n",
    "\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 sess.run(optimizer)\n",
    "#                 if flag:\n",
    "#                     # Get input and recover output images comparison\n",
    "#                     summ, target, output_ = sess.run([merged_summary_op, input_batch, output])\n",
    "#                     f, axarr = plt.subplots(FLAGS.test_image_number, 2)\n",
    "\n",
    "#                     for j in range(FLAGS.test_image_number):\n",
    "#                         for pos, im in enumerate([target, output_]):\n",
    "#                             axarr[j, pos].imshow(im[j].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "#                             axarr[j, pos].axis('off')\n",
    "#                             print(j)\n",
    "\n",
    "#                     plt.savefig(os.path.join(results_folder, 'Train/Epoch_{}').format(epoch))\n",
    "#                     plt.close(f)\n",
    "#                     flag = False\n",
    "#                     writer.add_summary(summ, epoch)\n",
    "\n",
    "#                     # Create artificial image from unit norm sample\n",
    "#                     artificial_image = sess.run(output, feed_dict={z: np.random.normal(0, 1, (1, FLAGS.latent_dim))})\n",
    "#                     plt.figure()\n",
    "#                     with sns.axes_style(\"white\"):\n",
    "#                         plt.imshow(artificial_image[0].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "#                     plt.savefig(os.path.join(results_folder, 'Test/{}'.format(epoch)))\n",
    "#                     plt.close()\n",
    "\n",
    "#                     # Create plot of latent space (only if latent dimensions are 2)\n",
    "#                     if FLAGS.latent_dim == 2 and FLAGS.plot_latent:\n",
    "#                         coords = sess.run(z, feed_dict={input_batch: test_images[..., np.newaxis]/255.})\n",
    "#                         colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "#                         plt.scatter(coords[:, 0], coords[:, 1], c=test_labels, cmap=colormap)\n",
    "\n",
    "#                         cbar = plt.colorbar()\n",
    "\n",
    "#                         plt.axis('off')\n",
    "#                         plt.title('Latent space')\n",
    "#                         plt.savefig(os.path.join(results_folder, 'Test/Latent_{}'.format(epoch)))\n",
    "#                         plt.close()\n",
    "\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 break\n",
    "\n",
    "# #         # Create mesh grid of values\n",
    "# #         values = np.arange(-3, 4, .5)\n",
    "# #         xx, yy = np.meshgrid(values, values)\n",
    "# #         input_holder = np.zeros((1, 2))\n",
    "# #         # Matrix that will contain the grid of images\n",
    "# #         container = np.zeros((28 * len(values), 28 * len(values)))\n",
    "\n",
    "# #         for row in range(xx.shape[0]):\n",
    "# #             for col in range(xx.shape[1]):\n",
    "# #                 input_holder[0, :] = [xx[row, col], yy[row, col]]\n",
    "# #                 artificial_image = sess.run(output, feed_dict={z: input_holder})\n",
    "# #                 container[row * 28: (row + 1) * 28, col * 28: (col + 1) * 28] = np.squeeze(artificial_image)\n",
    "\n",
    "# #         plt.imshow(container, cmap='gray')\n",
    "# #         plt.savefig(os.path.join(results_folder, 'Test/Space_{}'.format(epoch)))\n",
    "# #         plt.close(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
